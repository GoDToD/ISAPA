from flask import Flask, request, jsonify
from flask_cors import CORS
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import torch
import os

app = Flask(__name__)
CORS(app)

UPLOAD_FOLDER = 'uploads'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# ==== åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨4bité‡åŒ–ï¼‰ ====
bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)

model_path = "C:/Qwen2.5_8B_chat_dpo_finetune"  # ğŸš¨ ä¿®æ”¹æˆä½ çš„åˆå¹¶åçš„æ¨¡å‹è·¯å¾„ï¼

tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    device_map="auto",
    torch_dtype=torch.float16,
    quantization_config=bnb_config,
    trust_remote_code=True
)
model.eval()

# ==== èŠå¤©å†å²ç¼“å­˜ï¼ˆç®€å•ç‰ˆï¼‰
chat_history = []

# ==== èŠå¤©æ¥å£ ====
@app.route('/api/chat', methods=['POST'])
def chat():
    global chat_history
    data = request.json
    user_prompt = data.get('prompt', '')

    # æ·»åŠ åˆ°å†å²ï¼ˆroleåˆ†é…ï¼‰
    chat_history.append({"role": "user", "content": user_prompt})

    # system promptåªåœ¨æœ€å¼€å§‹åŠ ä¸€æ¬¡
    system_prompt = {"role": "system", "content": "You are a helpful assistant."}

    # æ„å»ºæœ€ç»ˆæ¶ˆæ¯åˆ—è¡¨
    messages = [system_prompt] + chat_history

    # ä½¿ç”¨æ­£ç¡®çš„chatæ¨¡æ¿
    input_ids = tokenizer.apply_chat_template(
        messages,
        add_generation_prompt=True,
        return_tensors="pt"
    ).to(model.device)

    # æ¨ç†
    with torch.no_grad():
        outputs = model.generate(
            input_ids=input_ids,
            max_new_tokens=512,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
            top_k=40,
            repetition_penalty=1.2,
            eos_token_id=tokenizer.eos_token_id
        )

    # è§£ç ï¼Œåªæ‹¿æ–°ç”Ÿæˆçš„éƒ¨åˆ†
    generated_text = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)
    generated_text = generated_text.strip()

    # æŠŠassistantå›ç­”ä¹ŸåŠ å…¥å†å²
    chat_history.append({"role": "assistant", "content": generated_text})

    return jsonify({"response": generated_text})

# ==== ä¸Šä¼ æ–‡ä»¶æ¥å£ ====
@app.route('/api/upload', methods=['POST'])
def upload_file():
    if 'file' not in request.files:
        return jsonify({"error": "No file uploaded."}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({"error": "No selected file."}), 400

    save_path = os.path.join(UPLOAD_FOLDER, file.filename)
    file.save(save_path)

    return jsonify({"message": f"File {file.filename} uploaded successfully."})

# ==== æ¸…ç©ºå†å²æ¥å£ï¼ˆå¯é€‰ï¼‰
@app.route('/api/reset', methods=['POST'])
def reset_chat():
    global chat_history
    chat_history = []
    return jsonify({"message": "Chat history cleared."})

# ==== å¯åŠ¨Flaskåº”ç”¨ ====
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
